# ğŸ“˜ Week 04 â€“ Theory & Unsupervised Learning

## ğŸ¯ Goals
- Learn about generalization theory and VC-dimension
- Explore regularization as a Bayesian prior
- Implement unsupervised learning algorithms (k-means, PCA)

---

## ğŸ§  Topics Covered
- Generalization bounds, VC-dimension (intro)
- Bayesian perspective on L2 regularization
- K-means clustering
- Principal Component Analysis (PCA)

---

## ğŸ“ Math Focus
- VC-dimension intuition
- Eigenvectors and eigenvalues
- L2 regularization as MAP estimation

---

## ğŸ’» Coding Tasks
- [ ] Implement K-means clustering
- [ ] Implement PCA using eigen decomposition
- [ ] Visualize dimensionality reduction results

---

## ğŸŒ Public Deliverables
- [ ] `unsupervised.ipynb`: k-means + PCA
- [ ] â€œL2 regularization = Gaussian priorâ€ math explanation
- [ ] (Optional) Blog post: *"How Unsupervised Learning Finds Structure"*

---

## ğŸ“š Resources
- ğŸ“¼ CS229 Lectures: 10â€“12
- ğŸ“˜ *Understanding ML*: Ch. 4â€“5, 19
- ğŸ“˜ *Murphy's ML Probabilistic Perspective*: Ch. 5
- ğŸ“º 3Blue1Brown: [Eigenvectors](https://www.youtube.com/watch?v=PFDu9oVAE-g)
