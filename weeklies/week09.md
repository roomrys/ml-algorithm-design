# 📘 Week 09 – Deep Learning Primer

## 🎯 Goals
- Understand neural networks and backpropagation
- Implement multilayer perceptron (MLP) from scratch
- Transition to PyTorch

---

## 🧠 Topics Covered
- Perceptrons and multilayer networks
- Backpropagation algorithm
- Activation functions and loss functions
- PyTorch basics

---

## 📐 Math Focus
- Chain rule for derivatives
- Forward and backward pass in MLP
- Gradient flow through layers

---

## 💻 Coding Tasks
- [ ] Implement 2-layer MLP from scratch (NumPy)
- [ ] Train and evaluate on toy dataset
- [ ] Re-implement in PyTorch

---

## 🌍 Public Deliverables
- [ ] `mlp_from_scratch.ipynb` and `mlp_pytorch.ipynb`
- [ ] Visuals of learned decision boundary
- [ ] Post: *"What Backprop Really Means"*

---

## 📚 Resources
- 📘 *Neural Networks & Deep Learning* (Nielsen, free online)
- 📘 *Deep Learning* (Goodfellow): Ch. 6
- 📼 CS231n: Lectures 1–3
